{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.data_utils import minibatches, pad_sequences, get_chunks\n",
    "from model.config import Config\n",
    "from model.data_utils import CoNLLDataset\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_classes = (str, bytes)\n",
    "def get_tensor(batch, pin, half=False):\n",
    "    if isinstance(batch, (np.ndarray, np.generic)):\n",
    "        batch = T(batch, half=half, cuda=False).contiguous()\n",
    "        if pin: batch = batch.pin_memory()\n",
    "        return to_gpu(batch)\n",
    "    elif isinstance(batch, string_classes):\n",
    "        return batch\n",
    "    elif isinstance(batch, collections.Mapping):\n",
    "        return {k: get_tensor(sample, pin, half) for k, sample in batch.items()}\n",
    "    elif isinstance(batch, collections.Sequence):\n",
    "        return [get_tensor(sample, pin, half) for sample in batch]\n",
    "    raise TypeError(f\"batch must contain numbers, dicts or lists; found {type(batch)}\")\n",
    "    \n",
    "class DataLoader(object):\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, pad_idx=0,\n",
    "                 num_workers=None, pin_memory=False, drop_last=False, pre_pad=True, half=False,\n",
    "                 transpose=False, transpose_y=False):\n",
    "        self.dataset,self.batch_size,self.num_workers = dataset,batch_size,num_workers\n",
    "        self.pin_memory,self.drop_last,self.pre_pad = pin_memory,drop_last,pre_pad\n",
    "        self.transpose,self.transpose_y,self.pad_idx,self.half = transpose,transpose_y,pad_idx,half\n",
    "\n",
    "        if batch_sampler is not None:\n",
    "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
    "                raise ValueError('batch_sampler is mutually exclusive with '\n",
    "                                 'batch_size, shuffle, sampler, and drop_last')\n",
    "\n",
    "        if sampler is not None and shuffle:\n",
    "            raise ValueError('sampler is mutually exclusive with shuffle')\n",
    "\n",
    "        if batch_sampler is None:\n",
    "            if sampler is None:\n",
    "                sampler = RandomSampler(dataset) if shuffle else SequentialSampler(dataset)\n",
    "            batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n",
    "\n",
    "        if num_workers is None:\n",
    "            self.num_workers = num_cpus()\n",
    "\n",
    "        self.sampler = sampler\n",
    "        self.batch_sampler = batch_sampler\n",
    "\n",
    "    def __len__(self): return len(self.batch_sampler)\n",
    "\n",
    "    def jag_stack(self, b):\n",
    "        if len(b[0].shape) not in (1,2): return np.stack(b)\n",
    "        ml = max(len(o) for o in b)\n",
    "        if min(len(o) for o in b)==ml: return np.stack(b)\n",
    "        res = np.zeros((len(b), ml), dtype=b[0].dtype) + self.pad_idx\n",
    "#         for i,o in enumerate(b):\n",
    "#             if self.pre_pad: res[i, -len(o):] = o\n",
    "#             else:            res[i,  :len(o)] = o\n",
    "        return res\n",
    "\n",
    "    def np_collate(self, batch):\n",
    "        b = batch[0]\n",
    "        if isinstance(b, (np.ndarray, np.generic)): return self.jag_stack(batch)\n",
    "        elif isinstance(b, (int, float)): return np.array(batch)\n",
    "        elif isinstance(b, string_classes): return batch\n",
    "        elif isinstance(b, collections.Mapping):\n",
    "            return {key: self.np_collate([d[key] for d in batch]) for key in b}\n",
    "        elif isinstance(b, collections.Sequence):\n",
    "            return [self.np_collate(samples) for samples in zip(*batch)]\n",
    "        raise TypeError((\"batch must contain numbers, dicts or lists; found {}\".format(type(b))))\n",
    "\n",
    "    def get_batch(self, indices):\n",
    "        res = self.np_collate([self.dataset[i] for i in indices])\n",
    "        if self.transpose:   res[0] = res[0].T\n",
    "        if self.transpose_y: res[1] = res[1].T\n",
    "        return res\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.num_workers==0:\n",
    "            for batch in map(self.get_batch, iter(self.batch_sampler)):\n",
    "                yield get_tensor(batch, self.pin_memory, self.half)\n",
    "        else:\n",
    "            with ThreadPoolExecutor(max_workers=self.num_workers) as e:\n",
    "                # avoid py3.6 issue where queue is infinite and can result in memory exhaustion\n",
    "                for c in chunk_iter(iter(self.batch_sampler), self.num_workers*10):\n",
    "                    for batch in e.map(self.get_batch, c):\n",
    "                        yield get_tensor(batch, self.pin_memory, self.half)\n",
    "\n",
    "class SeqDataLoader(DataLoader):\n",
    "    def get_batch(self, indices):\n",
    "        res = self.np_collate([self.dataset[i] for i in indices])\n",
    "        print(np.array(res).shape)\n",
    "        res[1] = np.reshape(res[1], -1)  # reshape the labels to one sequence\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CoNLLDataset(config.filename_train, config.processing_word,\n",
    "                         config.processing_tag, config.max_iter)\n",
    "val = CoNLLDataset(config.filename_dev, config.processing_word,\n",
    "                         config.processing_tag, config.max_iter)\n",
    "test = CoNLLDataset(config.filename_test, config.processing_word,\n",
    "                         config.processing_tag, config.max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatches(data, minibatch_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data: generator of (sentence, tags) tuples\n",
    "        minibatch_size: (int)\n",
    "    Yields:\n",
    "        list of tuples\n",
    "    \"\"\"\n",
    "    x_batch, y_batch = [], []\n",
    "    for (x, y) in data:\n",
    "        if len(x_batch) == minibatch_size:\n",
    "            yield x_batch, y_batch\n",
    "            x_batch, y_batch = [], []\n",
    "\n",
    "        if type(x[0]) == tuple:\n",
    "            x = zip(*x)\n",
    "        x_batch += [x]\n",
    "        y_batch += [y]\n",
    "\n",
    "    if len(x_batch) != 0:\n",
    "        yield x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sent, trn_lbls = [], []\n",
    "bs=40\n",
    "for sent, lbls in minibatches(train, bs):\n",
    "    char_ids, word_ids = zip(*sent)\n",
    "    word_ids, sequence_lengths = pad_sequences(word_ids, 0)\n",
    "    char_ids, word_lengths = pad_sequences(char_ids, pad_tok=0,\n",
    "        nlevels=2)\n",
    "\n",
    "    label_ids, label_lengths = pad_sequences(lbls, 0)\n",
    "    trn_sent.append(np.concatenate([ np.array(word_ids)[:,:, np.newaxis], np.array(char_ids) ], axis=-1))\n",
    "    trn_lbls.append(label_ids[0])\n",
    "    \n",
    "val_sent, val_lbls = [], []\n",
    "for sent, lbls in minibatches(val, bs):\n",
    "    char_ids, word_ids = zip(*sent)\n",
    "    word_ids, sequence_lengths = pad_sequences(word_ids, 0)\n",
    "    char_ids, word_lengths = pad_sequences(char_ids, pad_tok=0,\n",
    "        nlevels=2)\n",
    "    label_ids, label_lengths = pad_sequences(lbls, 0)\n",
    "    val_sent.append(np.concatenate([ np.array(word_ids)[:,:,np.newaxis], np.array(char_ids)], axis=-1))\n",
    "    val_lbls.append(label_ids[0])\n",
    "    \n",
    "test_sent, test_lbls = [], []\n",
    "for sent, lbls in minibatches(test,bs):\n",
    "    char_ids, word_ids = zip(*sent)\n",
    "    word_ids, sequence_lengths = pad_sequences(word_ids, 0)\n",
    "    char_ids, word_lengths = pad_sequences(char_ids, pad_tok=0,\n",
    "        nlevels=2)\n",
    "    label_ids, label_lengths = pad_sequences(lbls, 0)\n",
    "    test_sent.append(np.concatenate([ np.array(word_ids)[:,:,np.newaxis], np.array(char_ids)], axis=-1))\n",
    "    test_lbls.append(label_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/home/'\n",
    "trn_ds = TextSeqDataset(np.array(trn_sent), np.array(trn_lbls))\n",
    "val_ds = TextSeqDataset(np.array(val_sent), np.array(val_lbls))\n",
    "test_ds = TextSeqDataset(np.array(test_sent), np.array(test_lbls))\n",
    "\n",
    "trn_dl = SeqDataLoader(trn_ds, bs//2, transpose=False, num_workers=1, pre_pad=True)  # TODO why transpose? Should we also transpose the labels?\n",
    "val_dl = SeqDataLoader(val_ds, bs, transpose=False, num_workers=1, pre_pad=True)\n",
    "test_dl = SeqDataLoader(test_ds, bs, transpose=False, num_workers=1, pre_pad=True)\n",
    "md = ModelData(dir_path, trn_dl, val_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER_model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(NER_model, self).__init__()\n",
    "        self.config = config\n",
    "        self.idx_to_tag = {idx: tag for tag, idx in\n",
    "                           self.config.vocab_tags.items()}\n",
    "        self.get_word_embeddings()\n",
    "        self.get_logits()\n",
    "        \n",
    "    def get_word_embeddings(self):\n",
    "        # get word embeding\n",
    "        _word_embedding = V(self.config.embeddings, requires_grad=True)\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(_word_embedding)\n",
    "        \n",
    "        # get char embedding\n",
    "        self._char_embedding = nn.Embedding(self.config.nchars, self.config.dim_char)\n",
    "        self.char_embedding = nn.LSTM(input_size=self.config.dim_char, hidden_size=self.config.hidden_size_char,\n",
    "                                     num_layers=1, batch_first=True, # not sure here whether batch is first\n",
    "                                     bidirectional=True)\n",
    "        \n",
    "    def get_logits(self):\n",
    "        self.rnn = nn.LSTM(input_size=self.config.dim_word+self.config.dim_char*2,\n",
    "                          hidden_size=self.config.hidden_size_lstm,\n",
    "                          num_layers=1, batch_first=True, # not sure whether batch is first\n",
    "                          bidirectional=True)\n",
    "        self.dropout = nn.Dropout(self.config.dropout if self.train else 0)\n",
    "        self.linear = nn.Linear(self.config.hidden_size_lstm*2, self.config.ntags)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        char = input[:, :-1]\n",
    "        words = input[:, -1]\n",
    "        bs, sl, _ = char.size()\n",
    "        char = char.view(-1, _)\n",
    "        _char_embedding = self._char_embedding(char)\n",
    "        \n",
    "        char_embedding, (h_n, cell_n) = self.char_embedding(_char_embedding)\n",
    "        char_embedding = h_n.view(bs, sl, -1)\n",
    "        word_embedding = self.word_embedding(words)\n",
    "\n",
    "        # concat word embeddings and char embeddings\n",
    "        word_embedding = torch.cat([word_embedding, char_embedding], dim=-1)\n",
    "        word_embedding_dp = self.dropout(word_embedding)\n",
    "        \n",
    "        out, (n_h, n_cell) = self.rnn(word_embedding_dp)\n",
    "        out_dp = self.dropout(out)\n",
    "        out = self.linear(out_dp)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = NER_model(config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(ner_model.parameters(), 1e-3)\n",
    "loss_func = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d304400da5448fb10603aa384b6954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/703 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-5f65e91099f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/fs-object-detection/sequence_tagging_folder/sequence_tagging_pytorch/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs-object-detection/sequence_tagging_folder/sequence_tagging_pytorch/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-281-e6298ab207d8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0m_char_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_char_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "fit(ner_model, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = 4\n",
    "# for i in range(epoch):\n",
    "#     for step, (X_batch, Y_batch) in enumerate(trn_dl):\n",
    "#         print(step)\n",
    "#         Y = ner_model(X_batch)\n",
    "        \n",
    "# #         bs, sl = Y_batch[0].size()\n",
    "# #         Y_batch = Y_batch[0].view(-1)\n",
    "        \n",
    "\n",
    "# #         Y_onehot = torch.zeros(bs*sl, 8).cuda()\n",
    "# #         print(Y_onehot.size())\n",
    "# #         Y_onehot.scatter_(1, Y_batch)\n",
    "#         _, prediction = torch.max(Y, dim=-1)\n",
    "#         print(prediction.size())\n",
    "#         print(Y_batch[0].size())\n",
    "#         print(V(prediction))\n",
    "#         loss = loss_func(prediction, Y_batch[0])\n",
    "#         opt.zero_grad()\n",
    "#         loss.backward()\n",
    "#         opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
