{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.data_utils import minibatches, pad_sequences, get_chunks\n",
    "from model.config import Config\n",
    "from model.data_utils import CoNLLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CoNLLDataset(config.filename_train, config.processing_word,\n",
    "                         config.processing_tag, config.max_iter)\n",
    "val = CoNLLDataset(config.filename_dev, config.processing_word,\n",
    "                         config.processing_tag, config.max_iter)\n",
    "test = CoNLLDataset(config.filename_test, config.processing_word,\n",
    "                         config.processing_tag, config.max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class minibatches(data, minibatch_size):\n",
    "    def __init__(self, data, minibatch_size):\n",
    "        self.data = data\n",
    "        self.minibatch_size = minibatch_size\n",
    "        \n",
    "    def \n",
    "    x_batch, y_batch = [], []\n",
    "    for (x, y) in data:\n",
    "        if len(x_batch) == minibatch_size:\n",
    "            char_ids, word_ids = zip(*x_batch)\n",
    "            word_ids, sequence_lengths = pad_sequences(word_ids, 0)\n",
    "            char_ids, word_lengths = pad_sequences(char_ids, pad_tok=0,\n",
    "                nlevels=2)\n",
    "            labels, labels_idx = pad_sequences(y_batch, 0)\n",
    "            yield [T(char_ids), T(word_ids)], [T(labels)]\n",
    "            x_batch, y_batch = [], []\n",
    "\n",
    "        if type(x[0]) == tuple:\n",
    "            x = zip(*x)\n",
    "        x_batch += [x]\n",
    "        y_batch += [y]\n",
    "\n",
    "    if len(x_batch) != 0:\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER_model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(NER_model, self).__init__()\n",
    "        self.config = config\n",
    "        self.idx_to_tag = {idx: tag for tag, idx in\n",
    "                           self.config.vocab_tags.items()}\n",
    "        self.get_word_embeddings()\n",
    "        self.get_logits()\n",
    "        \n",
    "    def get_word_embeddings(self):\n",
    "        # get word embeding\n",
    "        _word_embedding = V(self.config.embeddings, requires_grad=True)\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(_word_embedding)\n",
    "        \n",
    "        # get char embedding\n",
    "        self._char_embedding = nn.Embedding(self.config.nchars, self.config.dim_char)\n",
    "        self.char_embedding = nn.LSTM(input_size=self.config.dim_char, hidden_size=self.config.hidden_size_char,\n",
    "                                     num_layers=1, batch_first=True, # not sure here whether batch is first\n",
    "                                     bidirectional=True)\n",
    "        \n",
    "    def get_logits(self):\n",
    "        self.rnn = nn.LSTM(input_size=self.config.dim_word+self.config.dim_char*2,\n",
    "                          hidden_size=self.config.hidden_size_lstm,\n",
    "                          num_layers=1, batch_first=True, # not sure whether batch is first\n",
    "                          bidirectional=True)\n",
    "        self.dropout = nn.Dropout(self.config.dropout if self.train else 0)\n",
    "        self.linear = nn.Linear(self.config.hidden_size_lstm*2, self.config.ntags)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        char = input[0]\n",
    "        words = input[1]\n",
    "        bs, sl, _ = char.size()\n",
    "        char = char.view(-1, _)\n",
    "        _char_embedding = self._char_embedding(char)\n",
    "        \n",
    "        char_embedding, (h_n, cell_n) = self.char_embedding(_char_embedding)\n",
    "        char_embedding = h_n.view(bs, sl, -1)\n",
    "        word_embedding = self.word_embedding(words)\n",
    "\n",
    "        # concat word embeddings and char embeddings\n",
    "        word_embedding = torch.cat([word_embedding, char_embedding], dim=-1)\n",
    "        word_embedding_dp = self.dropout(word_embedding)\n",
    "        \n",
    "        out, (n_h, n_cell) = self.rnn(word_embedding_dp)\n",
    "        out_dp = self.dropout(out)\n",
    "        out = self.linear(out_dp)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (data, label) in enumerate(minibatches(train, 100)):\n",
    "#     char_ids, word_ids = zip(*data)\n",
    "#     word_ids, sequence_lengths = pad_sequences(word_ids, 0)\n",
    "#     char_ids, word_lengths = pad_sequences(char_ids, pad_tok=0,\n",
    "#         nlevels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = minibatches(train, 20)\n",
    "val_dl = minibatches(val, 20)\n",
    "test_dl = minibatches(test, 20)\n",
    "dir_path = '/home/'\n",
    "md = ModelData(dir_path, trn_dl, val_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = NER_model(config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fbeta_torch(y_true, y_pred, beta, threshold, eps=1e-9):\n",
    "#     y_pred = (y_pred.float() > threshold).float()\n",
    "#     y_true = y_true.float()\n",
    "#     tp = (y_pred * y_true).sum(dim=1)\n",
    "#     precision = tp / (y_pred.sum(dim=1)+eps)\n",
    "#     recall = tp / (y_true.sum(dim=1)+eps)\n",
    "#     return torch.mean(\n",
    "#         precision*recall / (precision*(beta**2)+recall+eps) * (1+beta**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(ner_model.parameters(), 1e-3)\n",
    "loss_func = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-5f65e91099f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/fs-object-detection/sequence_tagging_folder/sequence_tagging_pytorch/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mep_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mtot_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mcnt_phases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs-object-detection/sequence_tagging_folder/sequence_tagging_pytorch/fastai/model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mep_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mtot_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mcnt_phases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": [
    "fit(ner_model, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([20, 13])\n",
      "torch.Size([20, 13])\n",
      "tensor([[0, 4, 3, 1, 5, 1, 5, 1, 1, 1, 2, 1, 4],\n",
      "        [3, 3, 1, 1, 3, 7, 7, 3, 3, 3, 5, 3, 5],\n",
      "        [1, 1, 1, 3, 3, 3, 3, 1, 3, 3, 3, 6, 1],\n",
      "        [3, 7, 1, 3, 1, 7, 1, 0, 4, 3, 3, 5, 1],\n",
      "        [1, 1, 2, 1, 6, 1, 7, 3, 6, 1, 4, 3, 3],\n",
      "        [1, 3, 3, 3, 5, 5, 1, 5, 3, 3, 7, 0, 4],\n",
      "        [3, 1, 3, 1, 3, 3, 3, 3, 6, 3, 1, 0, 2],\n",
      "        [7, 0, 1, 3, 5, 5, 5, 5, 6, 4, 1, 0, 3],\n",
      "        [3, 0, 3, 0, 3, 6, 3, 6, 3, 3, 1, 5, 3],\n",
      "        [6, 1, 3, 6, 5, 5, 5, 3, 3, 3, 3, 3, 0],\n",
      "        [4, 4, 5, 5, 5, 5, 5, 4, 4, 7, 5, 4, 7],\n",
      "        [1, 0, 0, 5, 5, 0, 0, 0, 6, 0, 3, 5, 5],\n",
      "        [3, 7, 6, 3, 1, 6, 6, 5, 4, 0, 5, 3, 5],\n",
      "        [5, 1, 6, 2, 2, 2, 4, 4, 4, 6, 4, 7, 1],\n",
      "        [1, 3, 3, 3, 3, 7, 7, 4, 1, 0, 3, 7, 1],\n",
      "        [1, 3, 7, 1, 3, 1, 4, 4, 5, 5, 1, 7, 6],\n",
      "        [4, 3, 5, 4, 7, 7, 7, 3, 3, 0, 0, 0, 3],\n",
      "        [4, 7, 4, 7, 7, 4, 3, 1, 3, 3, 7, 6, 4],\n",
      "        [5, 5, 5, 5, 4, 3, 5, 3, 6, 3, 4, 7, 0],\n",
      "        [1, 4, 0, 4, 6, 1, 1, 1, 1, 3, 5, 3, 2]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2 or more dimensions (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-d6c97e996ee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected 2 or more dimensions (got {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2 or more dimensions (got 1)"
     ]
    }
   ],
   "source": [
    "epoch = 4\n",
    "for i in range(epoch):\n",
    "    for step, (X_batch, Y_batch) in enumerate(trn_dl):\n",
    "        print(step)\n",
    "        Y = ner_model(X_batch)\n",
    "        \n",
    "#         bs, sl = Y_batch[0].size()\n",
    "#         Y_batch = Y_batch[0].view(-1)\n",
    "        \n",
    "\n",
    "#         Y_onehot = torch.zeros(bs*sl, 8).cuda()\n",
    "#         print(Y_onehot.size())\n",
    "#         Y_onehot.scatter_(1, Y_batch)\n",
    "        _, prediction = torch.max(Y, dim=-1)\n",
    "        print(prediction.size())\n",
    "        print(Y_batch[0].size())\n",
    "        print(V(prediction))\n",
    "        loss = loss_func(prediction, Y_batch[0])\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
