{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/pytorch4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "from sebastian.eval import eval_ner\n",
    "from model.data_utils import minibatches, pad_sequences, get_chunks\n",
    "from model.config import Config\n",
    "from model.data_utils import CoNLLDataset\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler, BatchSampler\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from UTILS.lstm_v import LSTM_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CoNLLDataset(config.filename_train, config.processing_word,\n",
    "                         config.processing_tag, config.max_iter)\n",
    "val = CoNLLDataset(config.filename_dev, config.processing_word,\n",
    "                         config.processing_tag, config.max_iter)\n",
    "test = CoNLLDataset(config.filename_test, config.processing_word,\n",
    "                         config.processing_tag, config.max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Minibatch(object):\n",
    "    def __init__(self, data, minibatch_size):\n",
    "        self.data = data\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.length = None\n",
    "        \n",
    "    def __iter__(self):\n",
    "        x_batch, y_batch = [], []\n",
    "        for (x, y) in self.data:\n",
    "            if len(x_batch) == self.minibatch_size:\n",
    "                char_ids, word_ids = zip(*x_batch)\n",
    "                word_ids, sequence_lengths = pad_sequences(word_ids, 0)\n",
    "                char_ids, word_lengths = pad_sequences(char_ids, pad_tok=0,\n",
    "                    nlevels=2)\n",
    "                lbl_ids, lbl_lengths = pad_sequences(y_batch, 0)\n",
    "                bs, sl, char = np.array(char_ids).shape\n",
    "                # expand the seq_lens and pad with ones, and concat with the rest\n",
    "                # seq_len (bs)\n",
    "                seq_lens_padded = np.concatenate([np.array(sequence_lengths)[:,np.newaxis], np.ones((bs, sl-1))], axis=-1)\n",
    "                # seq_len, word_ids, word_length, char_ids\n",
    "                word_ids = np.concatenate([seq_lens_padded[:,:,None], \n",
    "                                           np.array(word_ids)[:,:,None], \n",
    "                                           np.array(word_lengths)[:,:,None], \n",
    "                                           np.array(char_ids)], axis=-1)\n",
    "                \n",
    "                yield T(word_ids), T(lbl_ids).view(-1)\n",
    "                x_batch, y_batch = [], []\n",
    "\n",
    "            if type(x[0]) == tuple:\n",
    "                x = zip(*x)\n",
    "            x_batch += [x]\n",
    "            y_batch += [y]\n",
    "\n",
    "#         if len(x_batch) != 0:\n",
    "#             char_ids, word_ids = zip(*x_batch)\n",
    "#             word_ids, sequence_lengths = pad_sequences(word_ids, 0)\n",
    "#             char_ids, word_lengths = pad_sequences(char_ids, pad_tok=0,\n",
    "#                 nlevels=2)\n",
    "#             lbl_ids, lbl_lengths = pad_sequences(y_batch, 0)\n",
    "#             word_ids = np.concatenate([np.array(word_ids)[:,:,np.newaxis], np.array(char_ids)], axis=-1)\n",
    "#             yield T(word_ids), T(lbl_ids).view(-1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.length == None:\n",
    "            self.length = 0\n",
    "            for _ in self:\n",
    "                self.length += 1\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/home/'\n",
    "trn_dl = Minibatch(train, 20)\n",
    "val_dl = Minibatch(val, 20)\n",
    "test_dl = Minibatch(test, 20)\n",
    "md = ModelData(dir_path, trn_dl, val_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER_model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(NER_model, self).__init__()\n",
    "        self.config = config\n",
    "        self.idx_to_tag = {idx: tag for tag, idx in\n",
    "                           self.config.vocab_tags.items()}\n",
    "        self.get_word_embeddings()\n",
    "        self.get_logits()\n",
    "        \n",
    "    def get_word_embeddings(self):\n",
    "        # get word embeding\n",
    "        _word_embedding = V(self.config.embeddings, requires_grad=True)\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(_word_embedding)\n",
    "        \n",
    "        # get char embedding\n",
    "        self._char_embedding = nn.Embedding(self.config.nchars, self.config.dim_char)\n",
    "        self.char_embedding = LSTM_v1(input_size=self.config.dim_char, hidden_size=self.config.hidden_size_char,\n",
    "                                     num_layers=1, batch_first=True, # not sure here whether batch is first\n",
    "                                     bidirectional=True)\n",
    "        # get char embed for tar lang\n",
    "        self._char_embedding_tar = nn.Embedding(self.config.nchars, self.config.dim_char)\n",
    "        self.char_embedding_tar = LSTM_v1(input_size=self.config.dim_char, hidden_size=self.config.hidden_size_char,\n",
    "                                     num_layers=1, batch_first=True, # not sure here whether batch is first\n",
    "                                     bidirectional=True)\n",
    "        \n",
    "    def get_logits(self):\n",
    "        self.rnn = LSTM_v1(input_size=self.config.dim_word+self.config.dim_char*2,\n",
    "                          hidden_size=self.config.hidden_size_lstm,\n",
    "                          num_layers=1, batch_first=True, # not sure whether batch is first\n",
    "                          bidirectional=True)\n",
    "        self.dropout_e = nn.Dropout(self.config.dropout if self.train else 0) # e for embedding\n",
    "        self.dropout = nn.Dropout(self.config.dropout if self.train else 0)\n",
    "        self.linear = nn.Linear(self.config.hidden_size_lstm*2, self.config.ntags)\n",
    "        \n",
    "        # add logits for tar lang\n",
    "        self.rnn_tar = LSTM_v1(input_size=self.config.dim_word+self.config.dim_char*2,\n",
    "                          hidden_size=self.config.hidden_size_lstm,\n",
    "                          num_layers=1, batch_first=True, # not sure whether batch is first\n",
    "                          bidirectional=True)\n",
    "        self.dropout_e_tar = nn.Dropout(self.config.dropout if self.train else 0) # e for embedding\n",
    "        self.linear_tar = nn.Linear(self.config.hidden_size_lstm*4, self.config.ntags)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        seq_lens = input[:,0,0]\n",
    "        words = input[:, :, 1]\n",
    "        word_lens = input[:,:,2]\n",
    "        char = input[:, :, 3:]\n",
    "        \n",
    "        bs, sl, _ = char.size()\n",
    "        char = char.view(-1, _)\n",
    "        word_lens = word_lens.view(-1)\n",
    "        word_lens[word_lens==0] = 1\n",
    "        word_lens = word_lens.type(torch.int)\n",
    "        \n",
    "        # for source lang\n",
    "        _char_embedding = self._char_embedding(char.long()) \n",
    "        char_embedding, (h_n, cell_n) = self.char_embedding.run(_char_embedding, word_lens) # try use output instead of hidden size\n",
    "        char_embedding = h_n.contiguous().view(bs, sl, -1)\n",
    "        \n",
    "        # for tar lang\n",
    "        _char_embedding_tar = self._char_embedding_tar(char.long()) \n",
    "        char_embedding_tar, (h_n_tar, cell_n_tar) = self.char_embedding_tar.run(_char_embedding_tar, word_lens) # try use output instead of hidden size\n",
    "        char_embedding_tar = h_n_tar.contiguous().view(bs, sl, -1)\n",
    "        \n",
    "        # word embedding\n",
    "        word_embedding = self.word_embedding(words.long())\n",
    "        \n",
    "        seq_lens = seq_lens.type(torch.int)\n",
    "        \n",
    "        # concat word embeddings and char embeddings of source\n",
    "        # and to rnn\n",
    "        word_embedding = torch.cat([word_embedding, char_embedding], dim=-1)\n",
    "        word_embedding_dp = self.dropout_e(word_embedding)\n",
    "        seq_lens = seq_lens.type(torch.int)\n",
    "        out, (n_h, n_cell) = self.rnn.run(word_embedding_dp, seq_lens)\n",
    "        \n",
    "        # concat word embeddings and char embeddings of tar\n",
    "        # and to rnn\n",
    "        word_embedding_tar = torch.cat([word_embedding, char_embedding_tar], dim=-1)\n",
    "        word_embedding_dp_tar = self.dropout_e_tar(word_embedding_tar)\n",
    "        out_tar, (n_h_tar, n_cell_tar) = self.rnn_tar.run(word_embedding_dp_tar, seq_lens)\n",
    "        \n",
    "        # concat two outputs\n",
    "        out = torch.cat([out, out_tar], dim=-1)\n",
    "        \n",
    "        out_dp = self.dropout(out)\n",
    "        out = self.linear_tar(out_dp)\n",
    "        return out.view(out.size(0)*out.size(1), out.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = NER_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.ntags = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### rewrite RNN Learner #####\n",
    "'''rewrite load_encoder to load the encoding modules'''\n",
    "class RNN_Learner_bidir(Learner):\n",
    "    def __init__(self, data, models, **kwargs):\n",
    "        super().__init__(data, models, **kwargs)\n",
    "\n",
    "    def _get_crit(self, data): return F.cross_entropy\n",
    "    def fit(self, *args, **kwargs): return super().fit(*args, **kwargs, seq_first=True)\n",
    "\n",
    "    def save_encoder(self, name_rnn, name_linear, name_char_embedding, name_char_embedding_lstm): \n",
    "        torch.save(self.model.rnn.LSTM.state_dict(), name_rnn)\n",
    "        torch.save(self.model.linear.state_dict(), name_linear)\n",
    "        torch.save(self.model._char_embedding.state_dict(), name_char_embedding)\n",
    "        torch.save(self.model.char_embedding.LSTM.state_dict(), name_char_embedding_lstm)\n",
    "        \n",
    "    def load_encoder(self, name_rnn, name_linear, name_char_embedding, name_char_embedding_lstm): \n",
    "        self.model.rnn.LSTM.load_state_dict(torch.load(name_rnn))\n",
    "        self.model.linear.load_state_dict(torch.load(name_linear))\n",
    "        self.model._char_embedding.load_state_dict(torch.load(name_char_embedding))\n",
    "        self.model.char_embedding.LSTM.load_state_dict(torch.load(name_char_embedding_lstm))\n",
    "        \n",
    "##### end #####\n",
    "\n",
    "\n",
    "##### rewrite textmodel #####\n",
    "'''get layer groups'''\n",
    "class TextModel_bidir(BasicModel):\n",
    "    def get_layer_groups(self):\n",
    "        return [(self.model._char_embedding, self.model.char_embedding, self.model.rnn, self.model.linear),# source lang \n",
    "                (self.model._char_embedding_tar),(self.model.char_embedding_tar), \n",
    "                (self.model.word_embedding),(self.model.rnn_tar),(self.model.linear_tar)]\n",
    "\n",
    "def freeze_all_but(learner, n):\n",
    "    c=learner.get_layer_groups()\n",
    "    for l in c: set_trainable(l, False)\n",
    "    set_trainable(c[n], True)\n",
    "    \n",
    "def freeze_one(learner, n):\n",
    "    c=learner.get_layer_groups()\n",
    "    set_trainable(c[n], False)\n",
    "    \n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "learn = RNN_Learner_bidir(md, TextModel_bidir(to_gpu(ner_model)), opt_fn=opt_fn)\n",
    "learn.load_encoder('results/eng_rnn_params.pkl', 'results/eng_linear_params.pkl', 'results/eng_char_embedding_params.pkl', 'results/eng_char_embedding_lstm_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze_all_but(learn, -1)\n",
    "# learn.unfreeze()\n",
    "freeze_one(learn, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37c8611808b479290ab8a5c4712c2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/702 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 500, got 700",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cf7266cf7404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-4dd4f69bfe97>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_crit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_char_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_char_embedding_lstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs-object-detection/sequence_tagging_folder/sequence_tagging_pytorch/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs-object-detection/sequence_tagging_folder/sequence_tagging_pytorch/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs-object-detection/sequence_tagging_folder/sequence_tagging_pytorch/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs-object-detection/sequence_tagging_folder/sequence_tagging_pytorch/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4750c855c130>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mword_embedding_tar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_embedding_tar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mword_embedding_dp_tar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_e_tar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embedding_tar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mout_tar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_h_tar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cell_tar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_tar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embedding_dp_tar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# concat two outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fs-object-detection/sequence_tagging_folder/sequence_tagging_pytorch/UTILS/lstm_v.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, x, x_len)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx_emb_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;34m\"\"\"process using RNN\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mout_pack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_emb_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;34m\"\"\"unsort: h\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         ht = torch.transpose(ht, 0, 1)[\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    128\u001b[0m             raise RuntimeError(\n\u001b[1;32m    129\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 130\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 500, got 700"
     ]
    }
   ],
   "source": [
    "learn.fit(0.001, 3, metrics=[accuracy], cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learn.model.char_embedding.LSTM.state_dict(), 'results/eng_char_embedding_lstm_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NER_model(\n",
       "  (word_embedding): Embedding(17425, 300)\n",
       "  (_char_embedding): Embedding(84, 100)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (linear): Linear(in_features=600, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('results/eng_rnn_params.pkl', 'results/eng_linear_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2tag = [o for i,o in ner_model.idx_to_tag.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 measure overall: 0.8515127629903094\n",
      "{'precision-PER': 0.884896872920825, 'recall-PER': 0.8291770573566085, 'f1-measure-PER': 0.8561313163823125, 'precision-LOC': 0.9170996159927717, 'recall-LOC': 0.9339774557165862, 'f1-measure-LOC': 0.9254615910644589, 'precision-MISC': 0.7221350078492934, 'recall-MISC': 0.6628242074927952, 'f1-measure-MISC': 0.6912096168294015, 'precision-ORG': 0.7221195317313617, 'recall-ORG': 0.706875753920386, 'f1-measure-ORG': 0.7144163364827297, 'precision-overall': 0.8573870573870573, 'recall-overall': 0.8457184150307118, 'f1-measure-overall': 0.8515127629903094}\n",
      "Test token-level accuracy of NER model: 0.9817.\n"
     ]
    }
   ],
   "source": [
    "eval_ner(learn, id2tag, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "import torch.nn.utils.rnn as rnn_utils  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(10, 20, bidirectional=True, num_layers=1, batch_first=True)\n",
    "packed = rnn_utils.pack_padded_sequence(torch.randn(4, 50, 10), T([40, 30, 20, 10]), batch_first=True)\n",
    "packed_out, packed_hidden = lstm(packed)\n",
    "unpacked, unpacked_len = rnn_utils.pad_packed_sequence(packed_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0338,  0.0061,  0.0005,  ..., -0.0912,  0.0050,  0.1206],\n",
       "          [ 0.1199, -0.0857, -0.0399,  ..., -0.0580,  0.1510,  0.1029],\n",
       "          [-0.0035, -0.0643,  0.0095,  ..., -0.1064,  0.1615, -0.1207],\n",
       "          [ 0.2136, -0.0328, -0.1314,  ...,  0.0868,  0.0889, -0.0900]],\n",
       " \n",
       "         [[-0.0673, -0.0633, -0.0172,  ..., -0.1604,  0.0258, -0.0048],\n",
       "          [ 0.0453, -0.2590, -0.1192,  ..., -0.0744,  0.1925, -0.0982],\n",
       "          [-0.0232, -0.1782, -0.0328,  ..., -0.1592, -0.0142, -0.0713],\n",
       "          [ 0.1261,  0.0267, -0.0232,  ...,  0.1205,  0.0623, -0.0599]],\n",
       " \n",
       "         [[-0.1563,  0.1211, -0.0770,  ..., -0.2175,  0.1228, -0.0800],\n",
       "          [-0.0175, -0.2058, -0.0591,  ..., -0.0799,  0.2336, -0.0746],\n",
       "          [ 0.1256, -0.3455, -0.2181,  ..., -0.1456, -0.0381, -0.0669],\n",
       "          [-0.0260, -0.0122,  0.0984,  ...,  0.0678,  0.1064, -0.0934]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.1328, -0.0234,  0.0616,  ...,  0.0885,  0.0288, -0.0564],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.1971,  0.0140,  0.1158,  ..., -0.1061,  0.1983,  0.0058],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.0551,  0.0172, -0.0107,  ..., -0.0373, -0.0386,  0.1137],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "        grad_fn=<CopySlices>), tensor([40, 30, 20, 10]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpacked, unpacked_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rnn = LSTM_v1(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, h = v_rnn.run(torch.ones(4, 50, 10).cuda(), T([10,20,25,25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
